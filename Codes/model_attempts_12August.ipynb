{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "appointments = pd.read_csv('D:/DataIncubator_ChestXray/appointment_show_no-show/appointments_withFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110527, 39)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appointments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>DaysBeforeAppCat</th>\n",
       "      <th>NoShow</th>\n",
       "      <th>PreviousApp</th>\n",
       "      <th>PreviousNoShow</th>\n",
       "      <th>MissedAppointments</th>\n",
       "      <th>is_ITARARÉ</th>\n",
       "      <th>is_JESUS DE NAZARETH</th>\n",
       "      <th>is_SANTA CECÍLIA</th>\n",
       "      <th>is_SANTA CLARA</th>\n",
       "      <th>is_SANTOS DUMONT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.987250e+13</td>\n",
       "      <td>5642903</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T18:38:08Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; 45 days</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.589978e+14</td>\n",
       "      <td>5642503</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-29T16:08:27Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; 45 days</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.262962e+12</td>\n",
       "      <td>5642549</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:19:04Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; 45 days</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.679512e+11</td>\n",
       "      <td>5642828</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T17:29:31Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; 45 days</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841186e+12</td>\n",
       "      <td>5642494</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:07:23Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; 45 days</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientId  AppointmentID Gender          ScheduledDay  \\\n",
       "0  2.987250e+13        5642903      F  2016-04-29T18:38:08Z   \n",
       "1  5.589978e+14        5642503      M  2016-04-29T16:08:27Z   \n",
       "2  4.262962e+12        5642549      F  2016-04-29T16:19:04Z   \n",
       "3  8.679512e+11        5642828      F  2016-04-29T17:29:31Z   \n",
       "4  8.841186e+12        5642494      F  2016-04-29T16:07:23Z   \n",
       "\n",
       "         AppointmentDay  Age      Neighbourhood  Scholarship  Hipertension  \\\n",
       "0  2016-04-29T00:00:00Z   62    JARDIM DA PENHA            0             1   \n",
       "1  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             0   \n",
       "2  2016-04-29T00:00:00Z   62      MATA DA PRAIA            0             0   \n",
       "3  2016-04-29T00:00:00Z    8  PONTAL DE CAMBURI            0             0   \n",
       "4  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             1   \n",
       "\n",
       "   Diabetes       ...         DaysBeforeAppCat  NoShow  PreviousApp  \\\n",
       "0         0       ...                > 45 days   False            1   \n",
       "1         0       ...                > 45 days   False            1   \n",
       "2         0       ...                > 45 days   False            1   \n",
       "3         0       ...                > 45 days   False            1   \n",
       "4         1       ...                > 45 days   False            0   \n",
       "\n",
       "  PreviousNoShow MissedAppointments is_ITARARÉ is_JESUS DE NAZARETH  \\\n",
       "0            0.0                0.0          0                    0   \n",
       "1            0.0                0.0          0                    0   \n",
       "2            0.0                0.0          0                    0   \n",
       "3            0.0                1.0          0                    0   \n",
       "4            NaN                0.0          0                    0   \n",
       "\n",
       "   is_SANTA CECÍLIA  is_SANTA CLARA is_SANTOS DUMONT  \n",
       "0                 0               0                0  \n",
       "1                 0               0                0  \n",
       "2                 0               0                0  \n",
       "3                 0               0                0  \n",
       "4                 0               0                0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appointments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110527 entries, 0 to 110526\n",
      "Data columns (total 39 columns):\n",
      "PatientId                    110527 non-null float64\n",
      "AppointmentID                110527 non-null int64\n",
      "Gender                       110527 non-null object\n",
      "ScheduledDay                 110527 non-null object\n",
      "AppointmentDay               110527 non-null object\n",
      "Age                          110527 non-null int64\n",
      "Neighbourhood                110527 non-null object\n",
      "Scholarship                  110527 non-null int64\n",
      "Hipertension                 110527 non-null int64\n",
      "Diabetes                     110527 non-null int64\n",
      "Alcoholism                   110527 non-null int64\n",
      "Handcap                      110527 non-null int64\n",
      "SMS_received                 110527 non-null int64\n",
      "No-show                      110527 non-null object\n",
      "ScheduledDay_date            110527 non-null object\n",
      "AppointmentDay_date          110527 non-null object\n",
      "Scheduled_Day_of_week        110527 non-null object\n",
      "Scheduled_hour               110527 non-null int64\n",
      "Scheduled_minute             110527 non-null int64\n",
      "Scheduled_Month_of_year      110527 non-null object\n",
      "Scheduled_Day_of_month       110527 non-null int64\n",
      "Scheduled_year               110527 non-null int64\n",
      "Appointment_Day_of_week      110527 non-null object\n",
      "Appointment_Month_of_year    110527 non-null object\n",
      "Appointment_Day_of_month     110527 non-null int64\n",
      "Appointment_year             110527 non-null int64\n",
      "WeekdayScheduled             110527 non-null int64\n",
      "WeekdayAppointment           110527 non-null int64\n",
      "DaysBeforeApp                110527 non-null int64\n",
      "DaysBeforeAppCat             110527 non-null object\n",
      "NoShow                       110527 non-null bool\n",
      "PreviousApp                  110527 non-null int64\n",
      "PreviousNoShow               48228 non-null float64\n",
      "MissedAppointments           110527 non-null float64\n",
      "is_ITARARÉ                   110527 non-null int64\n",
      "is_JESUS DE NAZARETH         110527 non-null int64\n",
      "is_SANTA CECÍLIA             110527 non-null int64\n",
      "is_SANTA CLARA               110527 non-null int64\n",
      "is_SANTOS DUMONT             110527 non-null int64\n",
      "dtypes: bool(1), float64(3), int64(23), object(12)\n",
      "memory usage: 32.1+ MB\n"
     ]
    }
   ],
   "source": [
    "appointments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientId', 'AppointmentID', 'Gender', 'ScheduledDay',\n",
       "       'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension',\n",
       "       'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'No-show',\n",
       "       'ScheduledDay_date', 'AppointmentDay_date', 'Scheduled_Day_of_week',\n",
       "       'Scheduled_hour', 'Scheduled_minute', 'Scheduled_Month_of_year',\n",
       "       'Scheduled_Day_of_month', 'Scheduled_year', 'Appointment_Day_of_week',\n",
       "       'Appointment_Month_of_year', 'Appointment_Day_of_month',\n",
       "       'Appointment_year', 'WeekdayScheduled', 'WeekdayAppointment',\n",
       "       'DaysBeforeApp', 'DaysBeforeAppCat', 'NoShow', 'PreviousApp',\n",
       "       'PreviousNoShow', 'MissedAppointments', 'is_ITARARÉ',\n",
       "       'is_JESUS DE NAZARETH', 'is_SANTA CECÍLIA', 'is_SANTA CLARA',\n",
       "       'is_SANTOS DUMONT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appointments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "appointments = appointments[appointments['Age'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110526, 39)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appointments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = appointments[['Gender', 'Age', 'Scholarship', 'Hipertension','Diabetes', 'Alcoholism', 'Handcap', \n",
    "                         'SMS_received', 'WeekdayScheduled', 'WeekdayAppointment', 'Appointment_Month_of_year',\n",
    "                         'DaysBeforeAppCat', 'MissedAppointments', 'is_ITARARÉ','is_JESUS DE NAZARETH', 'PreviousApp',\n",
    "                         'is_SANTA CECÍLIA', 'is_SANTA CLARA','is_SANTOS DUMONT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(train)\n",
    "y = y = [0 if x == \"No\" else 1 for x in appointments['No-show']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Scholarship', 'Hipertension', 'Diabetes', 'Alcoholism',\n",
       "       'Handcap', 'SMS_received', 'WeekdayScheduled', 'WeekdayAppointment',\n",
       "       'MissedAppointments', 'is_ITARARÉ', 'is_JESUS DE NAZARETH',\n",
       "       'PreviousApp', 'is_SANTA CECÍLIA', 'is_SANTA CLARA', 'is_SANTOS DUMONT',\n",
       "       'Gender_F', 'Gender_M', 'Appointment_Month_of_year_April',\n",
       "       'Appointment_Month_of_year_June', 'Appointment_Month_of_year_May',\n",
       "       'DaysBeforeAppCat_0 days', 'DaysBeforeAppCat_1-2 days',\n",
       "       'DaysBeforeAppCat_20-30 days', 'DaysBeforeAppCat_3-7 days',\n",
       "       'DaysBeforeAppCat_30-45 days', 'DaysBeforeAppCat_8-20 days',\n",
       "       'DaysBeforeAppCat_> 45 days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 88207, 1: 22319})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88420, 28)\n",
      "(22106, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 70565, 1: 17855})\n",
      "Counter({0: 17642, 1: 4464})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train_val))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.925752092286813\n",
      "Best parameters: {'C': 10, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "params = {'penalty':['l1', 'l2'], 'C':[2, 3, 5, 10]}\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "clf = GridSearchCV(lr, param_grid = params, verbose=1, n_jobs = -1, cv=3)\n",
    "clf.fit(x_train_val, y_train_val)\n",
    "print('Best score: {}'.format(clf.best_score_))\n",
    "print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_best.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_best.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95     17642\n",
      "          1       0.72      0.98      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.92     22106\n",
      "\n",
      "0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95     17642\n",
      "          1       0.73      0.97      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.93     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96     17642\n",
      "          1       0.78      0.95      0.86      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96     17642\n",
      "          1       0.78      0.95      0.86      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96     17642\n",
      "          1       0.79      0.94      0.86      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96     17642\n",
      "          1       0.80      0.92      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    }
   ],
   "source": [
    "# params = {'C': [1, 3], 'kernel': ['rbf']}\n",
    "\n",
    "# svc = SVC(probability=True)\n",
    "# clf = GridSearchCV(svc, param_grid=params, verbose=1, n_jobs=-1, cv=2)\n",
    "# clf.fit(x_train_val, y_train_val)\n",
    "\n",
    "# print('Best score: {}'.format(clf.best_score_))\n",
    "# print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = svc_best.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95     17642\n",
      "          1       0.73      0.96      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.93     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = svc_best.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.90      0.94     17642\n",
      "          1       0.71      0.97      0.82      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.92     22106\n",
      "\n",
      "0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.90      0.95     17642\n",
      "          1       0.72      0.97      0.82      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.92     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95     17642\n",
      "          1       0.73      0.96      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.93     22106\n",
      "\n",
      "0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96     17642\n",
      "          1       0.77      0.95      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.94     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96     17642\n",
      "          1       0.78      0.95      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.94     22106\n",
      "\n",
      "0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.93      0.96     17642\n",
      "          1       0.78      0.94      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96     17642\n",
      "          1       0.80      0.92      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def with_threshold(y_pred, threshold):\n",
    "#     return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "# threshold = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "# for t in threshold:\n",
    "#     y_final=with_threshold(y_pred, t)\n",
    "#     print(t)\n",
    "#     print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9448427957475685\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 20, 'max_features': 10, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [300, 500], 'criterion': ['entropy'], 'max_depth': [5, 10, 20],\n",
    "          'max_features': [4, 6, 8, 10]}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "clf = GridSearchCV(rf, param_grid=params, n_jobs=-1, verbose=1, cv=2)\n",
    "clf.fit(x_train_val, y_train_val)\n",
    "print('Best score: {}'.format(clf.best_score_))\n",
    "print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_best.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.96     17642\n",
      "          1       0.80      0.94      0.86      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.94     22106\n",
      "\n",
      "0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96     17642\n",
      "          1       0.81      0.93      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.94     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.96     17642\n",
      "          1       0.83      0.91      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.94     22106\n",
      "\n",
      "0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.96     17642\n",
      "          1       0.84      0.89      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.94     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97     17642\n",
      "          1       0.86      0.87      0.86      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.95     22106\n",
      "\n",
      "0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.88      0.84      0.86      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97     17642\n",
      "          1       0.90      0.81      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = len([x for x in y_train_val if x == 0])\n",
    "\n",
    "y1 = len([x for x in y_train_val if x == 1])\n",
    "\n",
    "\n",
    "w0=(y1/y0)*2\n",
    "w1=1\n",
    "\n",
    "sample_weights = [w0 if x == 0 else w1 for x in y_train_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9502           10.74s\n",
      "         2           0.8902           10.40s\n",
      "         3           0.8804           10.28s\n",
      "         4           0.8766            9.83s\n",
      "         5           0.8278            9.96s\n",
      "         6           0.7967            9.84s\n",
      "         7           0.7568            9.91s\n",
      "         8           0.7198           10.03s\n",
      "         9           0.7134           10.06s\n",
      "        10           0.7018            9.92s\n",
      "        20           0.5344           10.02s\n",
      "        30           0.4401            9.72s\n",
      "        40           0.3867            9.38s\n",
      "        50           0.3501            8.99s\n",
      "        60           0.3235            8.56s\n",
      "        70           0.2985            8.31s\n",
      "        80           0.2862            7.92s\n",
      "        90           0.2764            7.59s\n",
      "       100           0.2644            7.24s\n",
      "       200           0.2159            3.50s\n",
      "       300           0.2029            0.00s\n",
      "Best score: 0.9475571137751639\n",
      "Best parameters: {'learning_rate': 0.05, 'loss': 'deviance', 'max_features': 8, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [300,400], 'learning_rate': [0.05, 0.1, 0.5], 'loss': [\"deviance\", \"exponential\"], \n",
    "          'max_features':[4, 6, 8, 10]}\n",
    "\n",
    "gbm = GradientBoostingClassifier(verbose=1)\n",
    "clf = GridSearchCV(gbm, param_grid=params, n_jobs=-1, verbose=1, cv=2)\n",
    "clf.fit(x_train_val, y_train_val, sample_weights)\n",
    "print('Best score: {}'.format(clf.best_score_))\n",
    "print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XD5FLnXXX9s4",
    "outputId": "6b0cf38f-3097-415e-9de8-691b35fcf1d4"
   },
   "outputs": [],
   "source": [
    "gbm_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "m0-hJ_BUX9s8",
    "outputId": "5eee8665-ff62-4da1-8fa3-890310ed721f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     17642\n",
      "          1       0.86      0.88      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm_best.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IYzGPyLX9s_"
   },
   "outputs": [],
   "source": [
    "y_pred = gbm_best.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UHgVClylCLnz",
    "outputId": "67473f0b-cfb0-4b8e-b24c-9a1cd85f0800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96     17642\n",
      "          1       0.81      0.94      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.94     22106\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.97     17642\n",
      "          1       0.82      0.92      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97     17642\n",
      "          1       0.84      0.91      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     17642\n",
      "          1       0.86      0.88      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97     17642\n",
      "          1       0.90      0.83      0.86      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97     17642\n",
      "          1       0.94      0.78      0.85      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.94     22106\n",
      "\n",
      "0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96     17642\n",
      "          1       0.96      0.74      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96     17642\n",
      "          1       0.98      0.71      0.82      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.93     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "nXaiOP7cCgDy",
    "outputId": "17044983-b7ce-4489-80a8-9b8341965faa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9473987785568876\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [200, 400, 500], 'learning_rate': [0.05, 0.1, 0.5], 'max_depth': [5, 10, 20]}\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier(verbosity=1)\n",
    "clf = GridSearchCV(xgb, param_grid=params, n_jobs=-1, verbose=1, cv=2)\n",
    "clf.fit(x_train_val, y_train_val, sample_weights)\n",
    "\n",
    "print('Best score: {}'.format(clf.best_score_))\n",
    "print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "y3svSRrbGOCD",
    "outputId": "f11a98ab-8864-4ce8-ae61-a49fd1a003aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     17642\n",
      "          1       0.87      0.87      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_best.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjeYgUKEGODD"
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_best.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XwyIFd3tGODO",
    "outputId": "b67f6def-8528-4184-a5c2-d43fe66ebb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.96     17642\n",
      "          1       0.82      0.92      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.95     22106\n",
      "\n",
      "0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97     17642\n",
      "          1       0.84      0.90      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     17642\n",
      "          1       0.87      0.87      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97     17642\n",
      "          1       0.91      0.82      0.86      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97     17642\n",
      "          1       0.95      0.76      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96     17642\n",
      "          1       0.97      0.73      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96     17642\n",
      "          1       0.99      0.71      0.82      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.8858063786473649\n",
      "Best Params {'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "params = {'n_neighbors' : [3, 5, 10, 15], 'p' : [1, 2, 5, 10], 'weights':['uniform', 'distance']}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "clf = GridSearchCV(knn, param_grid=params, verbose=1, n_jobs=-1, cv=2)\n",
    "clf.fit(x_train_val, y_train_val)\n",
    "print('Best Score {}'.format(clf.best_score_))\n",
    "print('Best Params {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "y3svSRrbGOCD",
    "outputId": "f11a98ab-8864-4ce8-ae61-a49fd1a003aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94     17642\n",
      "          1       0.88      0.58      0.70      4464\n",
      "\n",
      "avg / total       0.90      0.90      0.89     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_best.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjeYgUKEGODD"
   },
   "outputs": [],
   "source": [
    "y_pred = knn_best.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XwyIFd3tGODO",
    "outputId": "b67f6def-8528-4184-a5c2-d43fe66ebb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.92      0.94     17642\n",
      "          1       0.74      0.86      0.80      4464\n",
      "\n",
      "avg / total       0.92      0.91      0.91     22106\n",
      "\n",
      "0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.95     17642\n",
      "          1       0.79      0.82      0.80      4464\n",
      "\n",
      "avg / total       0.92      0.92      0.92     22106\n",
      "\n",
      "0.35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95     17642\n",
      "          1       0.82      0.77      0.80      4464\n",
      "\n",
      "avg / total       0.92      0.92      0.92     22106\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95     17642\n",
      "          1       0.85      0.72      0.78      4464\n",
      "\n",
      "avg / total       0.92      0.92      0.92     22106\n",
      "\n",
      "0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95     17642\n",
      "          1       0.86      0.66      0.75      4464\n",
      "\n",
      "avg / total       0.91      0.91      0.90     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94     17642\n",
      "          1       0.88      0.61      0.72      4464\n",
      "\n",
      "avg / total       0.90      0.90      0.90     22106\n",
      "\n",
      "0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.93     17642\n",
      "          1       0.90      0.51      0.65      4464\n",
      "\n",
      "avg / total       0.89      0.89      0.88     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93     17642\n",
      "          1       0.91      0.45      0.61      4464\n",
      "\n",
      "avg / total       0.88      0.88      0.86     22106\n",
      "\n",
      "0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92     17642\n",
      "          1       0.92      0.37      0.53      4464\n",
      "\n",
      "avg / total       0.87      0.87      0.84     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92     17642\n",
      "          1       0.92      0.31      0.47      4464\n",
      "\n",
      "avg / total       0.87      0.86      0.83     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 206.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 589.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9467541280253337\n",
      "Best parameters: {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 15, 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {'activation':['logistic','relu'], 'hidden_layer_sizes':[10,15,25], 'alpha':[1e-4, 1e-3, 1e-2, 1e-1], \n",
    "          'solver':['lbfgs','sgd'], 'learning_rate':['constant', 'adaptive']}\n",
    "\n",
    "nnet = MLPClassifier()\n",
    "clf = GridSearchCV(nnet, param_grid=params, verbose=1, cv=2, n_jobs=-1)\n",
    "clf.fit(x_train_val, y_train_val)\n",
    "\n",
    "print('Best score: {}'.format(clf.best_score_))\n",
    "print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "y3svSRrbGOCD",
    "outputId": "f11a98ab-8864-4ce8-ae61-a49fd1a003aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96     17642\n",
      "          1       0.92      0.75      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nnet_best.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjeYgUKEGODD"
   },
   "outputs": [],
   "source": [
    "y_pred = nnet_best.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XwyIFd3tGODO",
    "outputId": "b67f6def-8528-4184-a5c2-d43fe66ebb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95     17642\n",
      "          1       0.73      0.98      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.92     22106\n",
      "\n",
      "0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95     17642\n",
      "          1       0.73      0.97      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.93     22106\n",
      "\n",
      "0.35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.74      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.76      0.94      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.96     17642\n",
      "          1       0.80      0.89      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.94     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96     17642\n",
      "          1       0.92      0.75      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96     17642\n",
      "          1       0.94      0.72      0.82      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.93     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96     17642\n",
      "          1       0.97      0.69      0.81      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96     17642\n",
      "          1       0.98      0.68      0.80      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96     17642\n",
      "          1       0.99      0.67      0.80      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plqwzyMUGZyD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voted_class = VotingClassifier(estimators=[('lr', log_best),('rf', rf_best), ('gbm', gbm_best), \n",
    "                                           ('xgb', xgb_best),('nnet', nnet_best)], voting='soft', n_jobs=-1)\n",
    "\n",
    "voted_class.fit(x_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZJRtNvUHENh"
   },
   "outputs": [],
   "source": [
    "y_pred = voted_class.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wLExPiGnHENo",
    "outputId": "67473f0b-cfb0-4b8e-b24c-9a1cd85f0800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93     17642\n",
      "          1       0.67      1.00      0.80      4464\n",
      "\n",
      "avg / total       0.93      0.90      0.91     22106\n",
      "\n",
      "0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95     17642\n",
      "          1       0.71      0.99      0.83      4464\n",
      "\n",
      "avg / total       0.94      0.92      0.92     22106\n",
      "\n",
      "0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.96     17642\n",
      "          1       0.76      0.97      0.85      4464\n",
      "\n",
      "avg / total       0.95      0.93      0.94     22106\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.96     17642\n",
      "          1       0.80      0.95      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.94     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.97     17642\n",
      "          1       0.83      0.91      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.85      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97     17642\n",
      "          1       0.96      0.76      0.85      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.94     22106\n",
      "\n",
      "0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96     17642\n",
      "          1       0.99      0.70      0.82      4464\n",
      "\n",
      "avg / total       0.94      0.94      0.93     22106\n",
      "\n",
      "0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96     17642\n",
      "          1       1.00      0.68      0.81      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(model, x_train, y_train, test, n_fold):\n",
    "    folds = StratifiedKFold(n_splits=n_fold)\n",
    "    test_pred=np.empty((0))\n",
    "    train_pred = np.empty((0))\n",
    "    \n",
    "    for train_idx, val_idx in folds.split(x_train, y_train):\n",
    "        X_train, X_val, Y_train, Y_val = x_train.iloc[train_idx], x_train.iloc[val_idx], y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        train_pred = np.append(train_pred, model.predict(X_val), axis=0)\n",
    "        \n",
    "    test_pred = np.append(test_pred, model.predict(test), axis=0)\n",
    "    return test_pred, train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train_val)\n",
    "y_train.columns = [\"No-show\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=20, max_features=10,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.05, loss='deviance', max_depth=3,\n",
      "              max_features=8, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
      "              warm_start=False)\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9502            9.34s\n",
      "         2           0.9463            6.98s\n",
      "         3           0.9127            6.19s\n",
      "         4           0.9070            4.62s\n",
      "         5           0.8701            4.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6           0.8530            5.36s\n",
      "         7           0.8058            5.53s\n",
      "         8           0.7705            5.73s\n",
      "         9           0.7639            5.60s\n",
      "        10           0.7577            5.71s\n",
      "        20           0.6175            5.58s\n",
      "        30           0.4852            4.97s\n",
      "        40           0.4194            5.14s\n",
      "        50           0.3634            5.03s\n",
      "        60           0.3249            4.72s\n",
      "        70           0.2929            4.49s\n",
      "        80           0.2779            4.25s\n",
      "        90           0.2658            4.17s\n",
      "       100           0.2579            4.01s\n",
      "       200           0.2142            2.05s\n",
      "       300           0.2037            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9499            3.57s\n",
      "         2           0.8979            3.86s\n",
      "         3           0.8650            4.54s\n",
      "         4           0.8165            4.65s\n",
      "         5           0.7785            4.71s\n",
      "         6           0.7401            4.69s\n",
      "         7           0.7346            4.72s\n",
      "         8           0.7295            4.73s\n",
      "         9           0.7163            4.74s\n",
      "        10           0.7121            4.77s\n",
      "        20           0.5608            4.51s\n",
      "        30           0.4583            4.30s\n",
      "        40           0.3889            4.23s\n",
      "        50           0.3527            4.05s\n",
      "        60           0.3204            3.88s\n",
      "        70           0.2997            3.77s\n",
      "        80           0.2874            3.57s\n",
      "        90           0.2747            3.39s\n",
      "       100           0.2611            3.26s\n",
      "       200           0.2093            1.65s\n",
      "       300           0.1964            0.00s\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.05,\n",
      "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
      "       n_estimators=200, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
      "       subsample=1, verbosity=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=15, learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "models = [log_best, rf_best, gbm_best, xgb_best, nnet_best]\n",
    "df_ensemble_train = pd.DataFrame()\n",
    "df_ensemble_test = pd.DataFrame()\n",
    "\n",
    "x_train_val = pd.DataFrame(x_train_val)\n",
    "x_train_val.columns = x.columns\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    test_pred, train_pred = Stacking(model, x_train_val, y_train, x_test, 2)\n",
    "    \n",
    "    test_df = pd.DataFrame(test_pred)\n",
    "    train_df = pd.DataFrame(train_pred)\n",
    "    \n",
    "    df_ensemble_train = pd.concat([df_ensemble_train, train_df], axis=1)\n",
    "    df_ensemble_test = pd.concat([df_ensemble_test, test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_train_dummies = pd.DataFrame(pd.get_dummies(df_ensemble_train))\n",
    "df_ensemble_train_dummies.columns = [\"lr\", \"rf\", 'gbm', 'xgb', 'nnet']\n",
    "df_ensemble_test_dummies = pd.DataFrame(pd.get_dummies(df_ensemble_test))\n",
    "df_ensemble_test_dummies.columns = [\"lr\", \"rf\", 'gbm', 'xgb', 'nnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "xgb_best = XGBClassifier(learning_rate=0.05, max_depth=10, n_estimators=400,verbosity=1).fit(df_ensemble_train_dummies, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  1.6min finished\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9470368694865415\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [200, 400, 500], 'learning_rate': [0.05, 0.1, 0.5], 'max_depth': [5, 10, 20]}\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier(verbosity=1)\n",
    "clf = GridSearchCV(xgb, param_grid=params, n_jobs=-1, verbose=1, cv=2)\n",
    "clf.fit(df_ensemble_train_dummies, y_train)\n",
    "\n",
    "print('Best score: {}'.format(clf.best_score_))\n",
    "print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ensemble = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_ensemble.predict_proba(df_ensemble_test_dummies)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.96     17642\n",
      "          1       0.82      0.93      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.95     22106\n",
      "\n",
      "0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.97     17642\n",
      "          1       0.83      0.92      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.97     17642\n",
      "          1       0.83      0.92      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     17642\n",
      "          1       0.87      0.87      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89     17642\n",
      "          1       0.00      0.00      0.00      4464\n",
      "\n",
      "avg / total       0.64      0.80      0.71     22106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.2min finished\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9337           14.31s\n",
      "         2           0.8736           13.37s\n",
      "         3           0.8222           12.12s\n",
      "         4           0.7776           10.83s\n",
      "         5           0.7383            9.87s\n",
      "         6           0.7032            9.22s\n",
      "         7           0.6717            8.78s\n",
      "         8           0.6433            8.42s\n",
      "         9           0.6174            8.20s\n",
      "        10           0.5939            8.10s\n",
      "        20           0.4403            8.10s\n",
      "        30           0.3678            7.71s\n",
      "        40           0.3323            7.07s\n",
      "        50           0.3154            6.82s\n",
      "        60           0.3073            6.41s\n",
      "        70           0.3036            6.18s\n",
      "        80           0.3021            5.95s\n",
      "        90           0.3014            5.59s\n",
      "       100           0.3012            5.21s\n",
      "       200           0.3006            2.61s\n",
      "       300           0.3006            0.00s\n",
      "Best score: 0.9472065143632662\n",
      "Best parameters: {'learning_rate': 0.05, 'loss': 'deviance', 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [300,400], 'learning_rate': [0.05, 0.1, 0.5], 'loss': [\"deviance\", \"exponential\"]}\n",
    "\n",
    "gbm = GradientBoostingClassifier(verbose=1)\n",
    "clf = GridSearchCV(gbm, param_grid=params, n_jobs=-1, verbose=1, cv=2)\n",
    "clf.fit(df_ensemble_train_dummies, y_train)\n",
    "\n",
    "print('Best score: {}'.format(clf.best_score_))\n",
    "print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_ensemble = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm_ensemble.predict_proba(df_ensemble_test_dummies)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.96     17642\n",
      "          1       0.82      0.93      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.95     22106\n",
      "\n",
      "0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.97     17642\n",
      "          1       0.83      0.92      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.97     17642\n",
      "          1       0.83      0.92      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     17642\n",
      "          1       0.87      0.87      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.88      0.85      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89     17642\n",
      "          1       0.00      0.00      0.00      4464\n",
      "\n",
      "avg / total       0.64      0.80      0.71     22106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.54, 0.6, 0.7, 0.8, 0.85, 0.9]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:   28.1s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   29.8s finished\n",
      "c:\\users\\shanu\\anaconda3\\envs\\dl-udacity-pytorch\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9241687401040488\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [300, 500], 'criterion': ['entropy'], 'max_depth': [5, 10, 20]}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "clf = GridSearchCV(rf, param_grid=params, n_jobs=-1, verbose=1, cv=2)\n",
    "clf.fit(df_ensemble_train_dummies, y_train)\n",
    "print('Best score: {}'.format(clf.best_score_))\n",
    "print('Best parameters: {}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_ensemble = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_ensemble.predict_proba(df_ensemble_test_dummies)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     17642\n",
      "          1       0.75      0.97      0.84      4464\n",
      "\n",
      "avg / total       0.94      0.93      0.93     22106\n",
      "\n",
      "0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.96     17642\n",
      "          1       0.82      0.93      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.95     22106\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.96     17642\n",
      "          1       0.82      0.93      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.94      0.95     22106\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.97     17642\n",
      "          1       0.83      0.92      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     17642\n",
      "          1       0.87      0.87      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n",
      "0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     17642\n",
      "          1       0.89      0.84      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def with_threshold(y_pred, threshold):\n",
    "    return [1 if y >= threshold else 0 for y in y_pred]\n",
    "\n",
    "threshold = [0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.54, 0.6, 0.7, 0.8, 0.85, 0.9]\n",
    "for t in threshold:\n",
    "    y_final=with_threshold(y_pred, t)\n",
    "    print(t)\n",
    "    print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most stable classifier we got from is gbm stacking ensemble and xgb stacking ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     17642\n",
      "          1       0.87      0.87      0.87      4464\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm_ensemble.predict_proba(df_ensemble_test_dummies)[:, 1]\n",
    "y_final = [1 if y >= 0.5 else 0 for y in y_pred]\n",
    "print(classification_report(y_test, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_final)\n",
    "sns.set()\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True,annot_kws={\"size\": 16}, ax=ax, fmt='.0f')\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "# ax.set_xticklabels([''] + labels)\n",
    "# ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
